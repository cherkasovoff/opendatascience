{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Open Machine Learning Course\n",
    "<center>\n",
    "Author: Yury Kashnitsky, Data Scientist at Mail.Ru Group\n",
    "\n",
    "This material is subject to the terms and conditions of the license [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Free use is permitted for any non-comercial purpose with an obligatory indication of the names of the authors and of the source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Assignment #6. Part 1\n",
    "### <center> Beating benchmarks in \"Catch Me If You Can: Intruder Detection through Webpage Session Tracking\"\n",
    "    \n",
    "[Competition](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2). The task is to beat \"Assignment 6 baseline\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../data/train_sessions.csv', index_col='session_id')\n",
    "X_test = pd.read_csv('../../data/test_sessions.csv', index_col='session_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate target feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "X_test[times] = X_test[times].apply(pd.to_datetime)\n",
    "\n",
    "with open(r\"../../data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_dict = dict([(v, k) for (k, v) in site_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_df.drop('target', axis=1), train_df['target']\n",
    "train_size = int(0.7 * train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = X.iloc[:train_size, :], X.iloc[train_size:, :]\n",
    "\n",
    "y_train, y_valid = y.iloc[:train_size], y.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sites:\n",
    "    X_train[i] = X_train[i].map(site_dict)\n",
    "    X_valid[i] = X_valid[i].map(site_dict)\n",
    "    X_test[i] = X_test[i].map(site_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>site6</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rr.office.microsoft.com</td>\n",
       "      <td>2014-02-20 10:02:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maps.google.com</td>\n",
       "      <td>2014-02-22 11:19:50</td>\n",
       "      <td>mts0.google.com</td>\n",
       "      <td>2014-02-22 11:19:50</td>\n",
       "      <td>khms0.google.com</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>mts0.google.com</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>mts1.google.com</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>khms1.google.com</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>khms0.google.com</td>\n",
       "      <td>2014-02-22 11:19:52</td>\n",
       "      <td>khms1.google.com</td>\n",
       "      <td>2014-02-22 11:19:52</td>\n",
       "      <td>193.164.197.30</td>\n",
       "      <td>2014-02-22 11:20:15</td>\n",
       "      <td>193.164.196.60</td>\n",
       "      <td>2014-02-22 11:20:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbk1.googleapis.com</td>\n",
       "      <td>2013-12-16 16:40:17</td>\n",
       "      <td>accounts.google.com</td>\n",
       "      <td>2013-12-16 16:40:18</td>\n",
       "      <td>cbk0.googleapis.com</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>cbk1.googleapis.com</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>accounts.google.com</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>cbk0.googleapis.com</td>\n",
       "      <td>2013-12-16 16:40:20</td>\n",
       "      <td>cbk0.googleapis.com</td>\n",
       "      <td>2013-12-16 16:40:21</td>\n",
       "      <td>cbk0.googleapis.com</td>\n",
       "      <td>2013-12-16 16:40:22</td>\n",
       "      <td>cbk0.googleapis.com</td>\n",
       "      <td>2013-12-16 16:40:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-03-28 10:52:12</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-03-28 10:52:42</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-03-28 10:53:12</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-03-28 10:53:42</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-03-28 10:54:12</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-03-28 10:54:42</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-03-28 10:55:12</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-03-28 10:55:42</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-03-28 10:56:12</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-03-28 10:56:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>apis.google.com</td>\n",
       "      <td>2014-02-28 10:53:05</td>\n",
       "      <td>fr.wikipedia.org</td>\n",
       "      <td>2014-02-28 10:55:22</td>\n",
       "      <td>bits.wikimedia.org</td>\n",
       "      <td>2014-02-28 10:55:22</td>\n",
       "      <td>meta.wikimedia.org</td>\n",
       "      <td>2014-02-28 10:55:23</td>\n",
       "      <td>fr.wikipedia.org</td>\n",
       "      <td>2014-02-28 10:55:23</td>\n",
       "      <td>meta.wikimedia.org</td>\n",
       "      <td>2014-02-28 10:55:59</td>\n",
       "      <td>bits.wikimedia.org</td>\n",
       "      <td>2014-02-28 10:55:59</td>\n",
       "      <td>fr.wikipedia.org</td>\n",
       "      <td>2014-02-28 10:55:59</td>\n",
       "      <td>fr.wikipedia.org</td>\n",
       "      <td>2014-02-28 10:57:06</td>\n",
       "      <td>meta.wikimedia.org</td>\n",
       "      <td>2014-02-28 10:57:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              site1               time1                site2  \\\n",
       "session_id                                                                     \n",
       "1           rr.office.microsoft.com 2014-02-20 10:02:45                  NaN   \n",
       "2                   maps.google.com 2014-02-22 11:19:50      mts0.google.com   \n",
       "3               cbk1.googleapis.com 2013-12-16 16:40:17  accounts.google.com   \n",
       "4                    annotathon.org 2014-03-28 10:52:12       annotathon.org   \n",
       "5                   apis.google.com 2014-02-28 10:53:05     fr.wikipedia.org   \n",
       "\n",
       "                         time2                site3               time3  \\\n",
       "session_id                                                                \n",
       "1                          NaT                  NaN                 NaT   \n",
       "2          2014-02-22 11:19:50     khms0.google.com 2014-02-22 11:19:51   \n",
       "3          2013-12-16 16:40:18  cbk0.googleapis.com 2013-12-16 16:40:19   \n",
       "4          2014-03-28 10:52:42       annotathon.org 2014-03-28 10:53:12   \n",
       "5          2014-02-28 10:55:22   bits.wikimedia.org 2014-02-28 10:55:22   \n",
       "\n",
       "                          site4               time4             site5  \\\n",
       "session_id                                                              \n",
       "1                           NaN                 NaT               NaN   \n",
       "2               mts0.google.com 2014-02-22 11:19:51   mts1.google.com   \n",
       "3           cbk1.googleapis.com 2013-12-16 16:40:19       twitter.com   \n",
       "4                annotathon.org 2014-03-28 10:53:42    annotathon.org   \n",
       "5            meta.wikimedia.org 2014-02-28 10:55:23  fr.wikipedia.org   \n",
       "\n",
       "                         time5                site6               time6  \\\n",
       "session_id                                                                \n",
       "1                          NaT                  NaN                 NaT   \n",
       "2          2014-02-22 11:19:51     khms1.google.com 2014-02-22 11:19:51   \n",
       "3          2013-12-16 16:40:19  accounts.google.com 2013-12-16 16:40:19   \n",
       "4          2014-03-28 10:54:12       annotathon.org 2014-03-28 10:54:42   \n",
       "5          2014-02-28 10:55:23   meta.wikimedia.org 2014-02-28 10:55:59   \n",
       "\n",
       "                          site7               time7                site8  \\\n",
       "session_id                                                                 \n",
       "1                           NaN                 NaT                  NaN   \n",
       "2              khms0.google.com 2014-02-22 11:19:52     khms1.google.com   \n",
       "3           cbk0.googleapis.com 2013-12-16 16:40:20  cbk0.googleapis.com   \n",
       "4                annotathon.org 2014-03-28 10:55:12       annotathon.org   \n",
       "5            bits.wikimedia.org 2014-02-28 10:55:59     fr.wikipedia.org   \n",
       "\n",
       "                         time8                site9               time9  \\\n",
       "session_id                                                                \n",
       "1                          NaT                  NaN                 NaT   \n",
       "2          2014-02-22 11:19:52       193.164.197.30 2014-02-22 11:20:15   \n",
       "3          2013-12-16 16:40:21  cbk0.googleapis.com 2013-12-16 16:40:22   \n",
       "4          2014-03-28 10:55:42       annotathon.org 2014-03-28 10:56:12   \n",
       "5          2014-02-28 10:55:59     fr.wikipedia.org 2014-02-28 10:57:06   \n",
       "\n",
       "                         site10              time10  \n",
       "session_id                                           \n",
       "1                           NaN                 NaT  \n",
       "2                193.164.196.60 2014-02-22 11:20:16  \n",
       "3           cbk0.googleapis.com 2013-12-16 16:40:24  \n",
       "4                annotathon.org 2014-03-28 10:56:42  \n",
       "5            meta.wikimedia.org 2014-02-28 10:57:11  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Tf-Idf features based on sites. You can use `ngram_range`=(1, 3) and `max_features`=100000 or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['sites'] = X_train['site1']\n",
    "X_valid['sites'] = X_valid['site1']\n",
    "X_test['sites'] = X_test['site1']\n",
    "for i in sites[1:]:\n",
    "    X_train['sites'] += ' ' + X_train[i].fillna('')\n",
    "    X_valid['sites'] += ' ' + X_valid[i].fillna('')\n",
    "    X_test['sites'] += ' ' + X_test[i].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=100000)\n",
    "\n",
    "X_train_vect = vectorizer.fit_transform(X_train['sites'])\n",
    "X_valid_vect = vectorizer.transform(X_valid['sites'])\n",
    "X_test_vect = vectorizer.transform(X_test['sites'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add features based on the session start time: hour, whether it's morning, day or night and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here\n",
    "X_train['start_time'] = [d.hour for d in X_train['time1']]\n",
    "X_valid['start_time'] = [d.hour for d in X_valid['time1']]\n",
    "X_test['start_time'] = [d.hour for d in X_test['time1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['morning'] = [1 if 4 < d < 12 else 0 for d in X_train.start_time]\n",
    "X_train['day'] = [1 if 12 < d < 20 else 0 for d in X_train.start_time]\n",
    "X_train['night'] = [1 if d < 4 or d > 20 else 0 for d in X_train.start_time]\n",
    "\n",
    "X_valid['morning'] = [1 if 4 < d < 12 else 0 for d in X_valid.start_time]\n",
    "X_valid['day'] = [1 if 12 < d < 20 else 0 for d in X_valid.start_time]\n",
    "X_valid['night'] = [1 if d < 4 or d > 20 else 0 for d in X_valid.start_time]\n",
    "\n",
    "X_test['morning'] = [1 if 4 < d < 12 else 0 for d in X_test.start_time]\n",
    "X_test['day'] = [1 if 12 < d < 20 else 0 for d in X_test.start_time]\n",
    "X_test['night'] = [1 if d < 4 or d > 20 else 0 for d in X_test.start_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale this features and combine then with Tf-Idf based on sites (you'll need `scipy.sparse.hstack`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features = ['morning', 'day', 'night']\n",
    "X_train_dates_scaled = scaler.fit_transform(X_train[features])\n",
    "X_valid_dates_scaled = scaler.transform(X_valid[features])\n",
    "X_test_dates_scaled = scaler.transform(X_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here\n",
    "X_train_new = hstack([X_train_vect, X_train_dates_scaled])\n",
    "X_valid_new = hstack([X_valid_vect, X_valid_dates_scaled])\n",
    "X_test_new = hstack([X_test_vect, X_test_dates_scaled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform cross-validation with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You code here\n",
    "lr_cv = LogisticRegressionCV(cv=3)\n",
    "lr_cv.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_cv.predict_proba(X_valid_new)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9757491935911209"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction for the test set and form a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = vstack([X_train_new, X_valid_new])\n",
    "lr_cv.fit(X_all, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lr_cv.predict_proba(X_test_new)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_submission_file(test_pred, \"assignment6_alice_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
